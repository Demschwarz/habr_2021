#Как я запускал классификацию изображений на домашнем кластере Apache Ignite ML

Я - студент университета, знаком с машинным обучением в рамках пройденного курса, есть
интерес к современным кластерным технологиям, конкретно Apache Ignite. Возникла идея
копнуть глубже, то есть немного разобраться с относительно не популярной (во всяком 
случае, в русскоязычном сегменте) библиотекой
[Apache Ignite Machine Learning](https://ignite.apache.org/docs/latest/machine-learning/machine-learning#machine-learning).
Под катом — история о том, как мне удалось запустить пример OneVsRestClassificationExample,
сначала пример сам по себе, а потом его же на датасете
[MNIST database of handwritten digits](https://www.openml.org/d/554).
Ну и еще немного про производительность кластера из одного и двух домашних ПК. Весь
получившийся код доступен в репозитории [HandwrittenSVM](??).

## История вопроса
Документация [Apache Ignite](https://ignite.apache.org/) описывает технологию как
"distributed supercomputer for low-latency calculations, .. and machine learning".
Захотелось проверить, как это все будет вести себя на датасете сколько-нибудь заметного размера, особенно
для кластера из нескольких узлов.

Изначально было интересно поработать с изображениями. Конкретно - с нейросетью, способной относить неизвестное
изображение к одному из заранее известных классов. Знаем, что для задач классификации одним из "классических"
алгоритмов является алгоритм
[SVM (Solving Vector Machine)](https://habr.com/ru/post/428503/).

## Начинаю работу
Изучаю документацию, нахожу там раздел
[multiclass classification](https://ignite.apache.org/docs/latest/machine-learning/multiclass-classification#multiclass-classification),
там говорится про мою задачу на примере Glass dataset из 
[UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Glass+Identification).
В репозитории Apache Ignite нахожу готовый код примера
[OneVsRestClassificationExample](https://github.com/apache/ignite/blob/master/examples/src/main/java/org/apache/ignite/examples/ml/multiclass/OneVsRestClassificationExample.java). 
Остается клонировать и запустить. 

Раздел [Getting Started](https://ignite.apache.org/docs/latest/machine-learning/machine-learning#getting-started)
обещает быстрый старт, ну я и пробую: клонирую, открываю, компилирую

Но что-то идет не так

![](https://habrastorage.org/webt/kv/po/qy/kvpoqyrz3dqumgh_sxvoanc1b6o.png)

С Maven и IntelliJ IDEA работаю недавно, как справляться с подобными ошибками,
не имею понятия.

Начинаю гуглить в поисках решения или хотя бы товарищей по несчастью
— попадается на глаза статья
[Как быстро загрузить большую таблицу в Apache Ignite через Key-Value API](https://habr.com/ru/post/526708/).
Отличает её от большинства статей то, что в её тексте есть ссылка на маленький репозиторий с кодом. Пробую клонировать/открыть
в IntelliJ Idea/скомпилировать/выполнить, все запускается и работает как обещано.
Почему-то [автор](@vtch) использует библиотеки из
[GRIDGAIN Community Edition](https://www.gridgain.com/products/in-memory-computing-platform),
заменяю в файле <strong>pom.xml</strong> на то же самое из APACHE Ignite, ибо продолжающееся студенчество вырабатывает 
у меня устойчивую приязнь к Open Source-продуктам.
Опять работает, вот с этого можно стартовать.

Делаю по образу и подобию свой собственный пустой проект, копирую туда пример OneVsRestClassificationExample,
еще некоторые файлы из репозитория Apache Ignite и нужные зависимости в pom.xml. Оказалось,
пример использует крошечный датасет 1987 года GLASS_IDENTIFICATION размером всего в 116 строк.

Классификация выполняется быстро, в кластере с одним узлом на моем домашнем ПК занимает буквально пару секунд.

![](https://habrastorage.org/webt/io/gj/tr/iogjtr91ntp6r_4vknoebcrns00.png)
## Как я искал другой датасет
Хочется протестировать алгоритм на более объёмном датасете. В поисках оного встречаю статью Алексея Зиновьева ([zaleslaw](??)) под названием 
[Apache Ignite ML: origins and development](https://zaleslaw.medium.com/apache-ignite-ml-origins-and-development-d49a19e67202).
В статье есть отсылки к питоновскому пакету scikit-learn, поиск по этой теме приводит к туториалу
[Image Classification with MNIST Dataset](https://debuggercafe.com/image-classification-with-mnist-dataset).
Туториал рассказывает, как с помощью scikit-learn загрузить датасет mnist_784, нарисовать на экране загруженное, 
обучить сеть на наборе из 60 тысяч рисунков и протестировать качество обучения еще на 10 тысячах.

Смотрю дальше, оказывается, что на kaggle.com
[выложен](https://www.kaggle.com/oddrationale/mnist-in-csv?select=mnist_test.csv)
этот же датасет в удобном для обработки виде. Загружаю два CSV-файла: тестовый 
mnist_test.csv(17.46 MB, 10 тысяч рисунков) и обучающий mnist_train.csv(104.56 MB, 60 тысяч рисунков).
Первая колонка в файле — метка класса изображения, далее следует рисунок размером 28 х 28 (то есть строка
из 784 чисел от 0 до 255). Датасет содержит рукописные изображения арабских цифр, поэтому метка класса — число
от 0 до 9. 

## Как заменить датасет
Задача по замене GLASS_IDENTIFICATION на mnist_784 оказалась несложной — в примере используется
enum [MLSandboxDatasets](ссылка_на_репозиторий), указывающий на расположение csv-файла в проекте. Там даже есть
параметр, указывающий на наличие заголовка в файле; первая колонка файла — метка класса. Формат данных
оказался тем же самым и добавление датасета свелось к добавлению строки

  ````
      MNIST_TRAIN_DATASET("sampleData/mnist_train.csv", true, ","),
  ````

## Запускаю и смотрю на время работы
Инструкция из
[Как быстро загрузить большую таблицу в Apache Ignite через Key-Value API](https://habr.com/ru/post/526708/),
говорит о том, как запустить кластер Apache Ignite в минимально достаточной конфигурации. Запускаю узел данных с выставленным в `true `параметром `peerClassLoadingEnabled` и дополнительно
запускаю свой клиентский узел `HandwrittenSVM.jar`, все это в разных окнах на одном хосте.

Важный момент: для того, чтобы запустить одновременно несколько узлов, необходимо в папке с установленным дистрибутивом
Apache Ignite в папку `libs` перетащить из подпапки `optional` папку `ignite-ml`.

Практика показывает, что стандартной выделяемой на узел данных памяти не хватает.

![](https://habrastorage.org/webt/ff/wa/oy/ffwaoy-msvcvte3wuqc4kabszcs.png)

При таких объёмах всё вылетает с ошибкой нехватки памяти. На моей машине установлены скромные 8 Гб оперативки,
один узел не справляется с объёмами.

![](https://habrastorage.org/webt/m4/ld/it/m4lditeybgackmj31bp_pupueio.png)

Приходится делить датасет на части и работать уже с ними. Таким образом, получаю датасеты размером 5000, 8000,
10000, 12000, 15000 записей. С датасетом в 15000 записей копьютер уже не справляется, выдавая те же ошибки, что
и на полном датасете `MNIST_TRAIN`. Соответственно, время работы удаётся замерить только на объёмах от пяти до
двенадцати тысяч записей.

Отдельно хочется сказать про замеры времени исполнения. Всматриваясь в код `OneVsRestClassificationExample.java`,
понимаю, что весь процесс делится на четыре задачи, из которых нас реально интересуют две:
`fillCacheWith` - заполнение кэша, `trainer.fit` - обучение сети. Замерял я время через `System.currentTimeMillis()`.
Результаты замеров на одном узле данных можно увидеть в итоговой таблице.

В распоряжении у меня есть ещё один компьютер, ровно с такими же скромными 8 Гб оперативной памяти.
Создав локальную сеть и соединив между собой два компа, прогоняю все датасеты заново, на клиентской ноде замеряя
время исполнения. Результаты замеров на кластере можно увидеть в итоговой таблице.

Итоговая таблица:

![](https://habrastorage.org/webt/u5/h1/gu/u5h1gu8lty_svvz8xrjg_ni3cgk.png)

В таблице выше указаны данные замеров работы процессов `fillCacheWith` и `trainer.fit` на датасетах в 5000, 8000, 10000
и 12000 строк на одном и двух одинаковых узлах данных.

Анализируя результаты, можем заключить: передача данных на второй узел данных по проводу и загрузка их в кэш занимает
какое-то время, если клиентский узел и узел данных запущены на одной машине, а второй узел данных - на другой,
то время общего заполнения кэша увеличится. Также можем наблюдать тенденцию к уменьшению времени обучения сети
при добавлении второго удалённого узла данных. Хоть на датасете в 5000 строк это и не наблюдается, но на более
обширных наборах данных всё работает так, как мы и ожидаем, время обучения сети уменьшается.